<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>StableLM 发展历程与深度解析</title>
    <script src="https://cdn.tailwindcss.com/3.4.1"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/particles.js/2.0.0/particles.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/marked/4.0.2/marked.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/framer-motion/10.16.4/framer-motion.umd.min.js"></script>
    <style>
        body {
            background-color: #1a1a2e; /* 深色背景 */
            color: #e0e0e0; /* 亮色文字 */
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            overflow-x: hidden;
        }
        #particles-js {
            position: fixed;
            width: 100%;
            height: 100%;
            top: 0;
            left: 0;
            z-index: -1; /* 确保在内容之下 */
        }
        .content-card {
            background: rgba(255, 255, 255, 0.05); /* 玻璃拟态背景 */
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 2rem;
            margin-bottom: 2rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 0 15px rgba(128, 0, 128, 0.3), 0 0 30px rgba(0, 0, 255, 0.2); /* 霓虹光效 */
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        .content-card:hover {
            transform: translateY(-10px) scale(1.02);
            box-shadow: 0 0 25px rgba(128, 0, 128, 0.6), 0 0 45px rgba(0, 0, 255, 0.4); /* 悬停发光效果 */
        }
        h1, h2, h3 {
            color: #9f7aea; /* 紫色标题 */
            font-weight: bold;
        }
        h1 { font-size: 2.5em; margin-bottom: 1em; text-align: center; }
        h2 { font-size: 2em; margin-top: 1.5em; margin-bottom: 0.8em; border-bottom: 2px solid #9f7aea; padding-bottom: 0.3em;}
        h3 { font-size: 1.5em; margin-top: 1em; margin-bottom: 0.5em; color: #63b3ed; }
        p, li {
            line-height: 1.8;
            margin-bottom: 1em;
            color: #c0c0c0;
        }
        ul { list-style-type: disc; margin-left: 20px; }
        strong { color: #a0aec0; }
        .reference-link {
            font-size: 0.8em;
            color: #63b3ed;
            text-decoration: none;
            margin-left: 5px;
        }
        .reference-link:hover {
            text-decoration: underline;
        }
        .icon {
            margin-right: 8px;
            color: #9f7aea;
        }
        .footer {
            text-align: center;
            padding: 2rem;
            margin-top: 3rem;
            background: rgba(0,0,0,0.2);
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }
        .footer a {
            color: #9f7aea;
            text-decoration: none;
        }
        .footer a:hover {
            text-decoration: underline;
        }
        /* 滚动动画的初始状态 */
        .scroll-animate {
            opacity: 0;
            transform: translateY(50px);
            transition: opacity 0.6s ease-out, transform 0.6s ease-out; /* Added transition for smoothness */
        }
    </style>
</head>
<body>
     <div id="particles-js"></div>
    <div class="container mx-auto px-4 py-8">
        <header class="my-12">
            <div class="flex justify-center items-center relative">
                <h1 class="text-5xl font-bold text-purple-400">StableLM 发展历程与深度解析</h1>
                <a href="StabilityAI StableLM1.html" class="absolute right-0 bg-purple-500 hover:bg-purple-700 text-white font-bold py-2 px-4 rounded-lg transition-colors duration-300">
                    趣闻
                </a>
            </div>
        </header>

        <main id="main-content">
            <!-- Markdown content will be inserted here by JavaScript -->
        </main>

        <footer class="footer">
            <p class="text-gray-400">信息来源：综合网络资源，包括但不限于维基百科、StableLM官网、各类科技媒体文章等。</p>
            <p>
                <a href="https://stability.ai" target="_blank" rel="noopener noreferrer">
                    <i class="fas fa-globe icon"></i>StableLM 官方网站
                </a>
            </p>
            <p class="mt-2 text-sm text-gray-500">&copy; 2024 AI Timeline Project. All rights reserved.</p>
        </footer>
    </div>

    <script>
        // Initialize Particles.js
        particlesJS('particles-js', {
            "particles": {
                "number": {
                    "value": 80,
                    "density": {
                        "enable": true,
                        "value_area": 800
                    }
                },
                "color": {
                    "value": "#ffffff"
                },
                "shape": {
                    "type": "circle",
                    "stroke": {
                        "width": 0,
                        "color": "#000000"
                    },
                    "polygon": {
                        "nb_sides": 5
                    }
                },
                "opacity": {
                    "value": 0.5,
                    "random": false,
                    "anim": {
                        "enable": false,
                        "speed": 1,
                        "opacity_min": 0.1,
                        "sync": false
                    }
                },
                "size": {
                    "value": 3,
                    "random": true,
                    "anim": {
                        "enable": false,
                        "speed": 40,
                        "size_min": 0.1,
                        "sync": false
                    }
                },
                "line_linked": {
                    "enable": true,
                    "distance": 150,
                    "color": "#ffffff",
                    "opacity": 0.4,
                    "width": 1
                },
                "move": {
                    "enable": true,
                    "speed": 6,
                    "direction": "none",
                    "random": false,
                    "straight": false,
                    "out_mode": "out",
                    "bounce": false,
                    "attract": {
                        "enable": false,
                        "rotateX": 600,
                        "rotateY": 1200
                    }
                }
            },
            "interactivity": {
                "detect_on": "canvas",
                "events": {
                    "onhover": {
                        "enable": true,
                        "mode": "repulse"
                    },
                    "onclick": {
                        "enable": true,
                        "mode": "push"
                    },
                    "resize": true
                },
                "modes": {
                    "grab": {
                        "distance": 400,
                        "line_linked": {
                            "opacity": 1
                        }
                    },
                    "bubble": {
                        "distance": 400,
                        "size": 40,
                        "duration": 2,
                        "opacity": 8,
                        "speed": 3
                    },
                    "repulse": {
                        "distance": 200,
                        "duration": 0.4
                    },
                    "push": {
                        "particles_nb": 4
                    },
                    "remove": {
                        "particles_nb": 2
                    }
                }
            },
            "retina_detect": true
        });

        const markdownContent = `
# StabilityAI StableLM 综合信息

## 一. 项目起始点和研究动机

Stability AI 推出 StableLM 系列大型语言模型，旨在提供一个开源的、可访问的、透明的 ChatGPT 等闭源模型的替代方案。其核心动机是推动人工智能技术的民主化，让更广泛的研究者、开发者和用户能够参与到大型语言模型的开发和应用中，并促进 AI 技术的透明、公平和可控发展。 <mcreference link="https://www.maginative.com/article/stability-ai-debuts-stablelm-accelerating-the-era-of-open-source-language-models/" index="3">3</mcreference> StableLM 的目标是生成文本和代码，并计划通过开源模型来减少偏见，提高模型的准确性和公平性。 <mcreference link="https://cryptosolopreneur.wordpress.com/2023/04/20/stabilityai-launches-stablelm-open-source-alternatives-to-chatgpt/" index="1">1</mcreference>

StableLM 主要由 **Stability AI** 公司开发。其内部的 **CarperAI** 团队也参与了特定模型的开发，例如 StableVicuna。 <mcreference link="https://github.com/Stability-AI/StableLM" index="1">1</mcreference>

## 二. 版本发布、技术改进和优势

### 2.1 StableLM-Alpha (初代版本)

*   **发布时间**：2023年4月 <mcreference link="https://www.theverge.com/2023/4/19/236897 StabilityAI-StableLM-large-language-model-chatgpt-competitor" index="None">None</mcreference>
*   **模型参数**：包含 30 亿 (3B) 和 70 亿 (7B) 参数的多个模型。 <mcreference link="https://www.maginative.com/article/stability-ai-debuts-stablelm-accelerating-the-era-of-open-source-language-models/" index="3">3</mcreference>
*   **训练数据**：基于一个包含 1.5 万亿 token 的大规模数据集进行训练，该数据集是 The Pile 数据集的扩展版本。 <mcreference link="https://www.maginative.com/article/stability-ai-debuts-stablelm-accelerating-the-era-of-open-source-language-models/" index="3">3</mcreference> <mcreference link="https://siliconangle.com/2023/04/19/stability-ai-releases-open-source-language-model/" index="5">5</mcreference>
*   **技术特点与优势**：尽管参数规模相对较小，但在对话和编码任务中表现出高性能。 <mcreference link="https://www.maginative.com/article/stability-ai-debuts-stablelm-accelerating-the-era-of-open-source-language-models/" index="3">3</mcreference> 同时发布了经过指令微调的 'StableLM-Tuned-Alpha' 版本，可用于类似 ChatGPT 的对话交互。 <mcreference link="https://github.com/Stability-AI/StableLM" index="1">1</mcreference>
*   **开源许可**：在 CC BY-SA-4.0 许可下发布，允许自由使用和修改。 <mcreference link="https://www.maginative.com/article/stability-ai-debuts-stablelm-accelerating-the-era-of-open-source-language-models/" index="3">3</mcreference>

### 2.2 StableVicuna-13B

*   **发布时间**：2023年4月 <mcreference link="https://github.com/Stability-AI/StableLM" index="None">None</mcreference>
*   **模型架构**：这是一个基于 LLaMA-13B 微调的 Vicuna-13B v0 模型，再通过强化学习人类反馈 (RLHF) 进行微调的聊天机器人。 <mcreference link="https://github.com/Stability-AI/StableLM" index="1">1</mcreference>
*   **技术特点与优势**：旨在创建一个开源的 RLHF LLM 聊天机器人。 <mcreference link="https://github.com/Stability-AI/StableLM" index="1">1</mcreference>

### 2.3 StableLM-3B-4E1T

*   **发布时间**：2023年9月 <mcreference link="https://github.com/Stability-AI/StableLM" index="None">None</mcreference>
*   **模型参数**：30 亿 (3B) 参数。
*   **技术特点与优势**：在 3B 参数规模下表现出色，达到了开源模型的最先进水平，并在多个基准测试中能与 7B 参数模型竞争。 <mcreference link="https://github.com/Stability-AI/StableLM" index="None">None</mcreference>

### 2.4 Stable LM 2 1.6B

*   **发布时间**：相关技术报告发布于2024年初。
*   **模型架构**：
    *   基于 LLaMA 架构，包含 32 层 Transformer。
    *   嵌入维度 (Embedding Dimension): 2048。
    *   注意力头 (Attention Heads): 32 个。
    *   使用了 SwiGLU 激活函数和 RoPE (Rotary Positional Embeddings)。
    *   支持 Grouped Query Attention (GQA) 以提高推理效率。
    *   上下文窗口 (Context Window): 4096 tokens。
*   **训练数据**：
    *   在包含多种语言（英语、西班牙语、德语、意大利语、法语、葡萄牙语、荷兰语）和代码的 **2 万亿 (2 Trillion) tokens** 数据集上进行预训练。
    *   主要数据源包括：Falcon RefinedWeb (经过 CCNet 过滤和去重)、StarCoder (用于代码数据) 以及学术文本如 ArXiv 和 PubMed Central。
    *   数据混合比例经过精心设计和消融实验，以平衡多语言能力和各项任务性能。
*   **性能指标与优势**：
    *   **多语言能力**：在多种语言（如西班牙语、德语、法语）的零样本和少样本评估中表现出色，显著优于其他类似规模的开源模型。
    *   **对话能力**：在 MT-Bench 评估中，其对话性能优于 Phi-2、Gemma 2B 和 TinyLLaMA 1.1B 等模型。
    *   **推理与量化**：支持多种量化格式（如 INT4、INT5、INT8、FP16），并提供了在 llama.cpp、Apple MLX 和 Intel OpenVINO 等推理框架上的量化权重，便于在边缘设备上部署。低精度量化（如 INT4）在吞吐量和功耗方面表现出优势。
    *   **技术创新**：
        *   使用了 **FlashAttention-2** 来优化注意力的计算效率和内存使用。
        *   开发了一种**混合学习率调度器**，结合了余弦衰减和逆平方根 (rsqrt) 调度器的优点，取得了更好的训练效果。
        *   通过“针在干草堆”(Needle-in-a-Haystack) 测试评估了模型在长上下文窗口下的检索能力，在 4096 tokens 内表现稳定。
*   **训练细节**：
    *   全局批量大小 (Global Batch Size): 选择了 1600 万 tokens 作为最佳折衷方案，以平衡训练速度和收敛性。
    *   训练碳足迹：估计其训练过程消耗了 30MWh 的电力，产生了约 11 吨二氧化碳排放。

## 三. 重要里程碑和成就

*   **2023年4月**：Stability AI 发布 StableLM Alpha 版本，标志着其正式进入开源大型语言模型领域，为市场提供了 ChatGPT 的一个有力替代品。 <mcreference link="https://www.theverge.com/2023/4/19/236897 StabilityAI-StableLM-large-language-model-chatgpt-competitor" index="None">None</mcreference>
*   **2023年9月**：发布的 StableLM-3B-4E1T 模型在 30 亿参数规模下达到了开源模型的最先进水平，证明了小模型通过优质数据和训练方法也能达到卓越性能。 <mcreference link="https://github.com/Stability-AI/StableLM" index="None">None</mcreference>
*   **Stable LM 2 1.6B 的发布**：进一步推动了小型高效语言模型的发展，特别是在多语言处理和边缘设备部署方面展现了强大潜力，其在 MT-Bench 等评估中超越了更大规模的模型。

## 四. 实际应用中的使用情况

StableLM 系列模型具有广泛的应用潜力，主要包括：

*   **文本生成**：可以生成各种类型的文本，如文章、故事、诗歌、邮件等。 <mcreference link="https://cryptosolopreneur.wordpress.com/2023/04/20/stabilityai-launches-stablelm-open-source-alternatives-to-chatgpt/" index="1">1</mcreference>
*   **代码生成**：能够根据自然语言描述生成代码片段或辅助编程。 <mcreference link="https://siliconangle.com/2023/04/19/stability-ai-releases-open-source-language-model/" index="5">5</mcreference>
*   **问答系统**：可以用于构建能够回答用户问题的智能助手或聊天机器人。 <mcreference link="https://cryptosolopreneur.wordpress.com/2023/04/20/stabilityai-launches-stablelm-open-source-alternatives-to-chatgpt/" index="1">1</mcreference>
*   **文本摘要**：能够将长文本概括为简短的摘要。 <mcreference link="https://cryptosolopreneur.wordpress.com/2023/04/20/stabilityai-launches-stablelm-open-source-alternatives-to-chatgpt/" index="1">1</mcreference>
*   **对话式AI**：'StableLM-Tuned-Alpha' 和 'StableVicuna' 等微调版本可以直接用于构建聊天机器人和虚拟助手。 <mcreference link="https://github.com/Stability-AI/StableLM" index="1">1</mcreference>
*   **下游应用开发**：作为开源模型，开发者可以基于 StableLM 进行微调，以适应特定的行业或任务需求，例如在金融、医疗、教育等领域。 <mcreference link="https://medium.com/@james_96581/stablelm-the-free-to-use-instruction-fine-tuned-natural-language-model-from-stability-ai-11dd0a110009" index="None">None</mcreference>
*   **研究与实验**：为学术界和研究社区提供了一个强大的平台，用于探索大型语言模型的行为、能力和局限性。

**具体案例**：
GitHub 上的 StableLM 项目页面提供了使用 'StableLM-Tuned-Alpha' 进行聊天的代码示例，展示了其作为对话式 AI 的直接应用。 <mcreference link="https://github.com/Stability-AI/StableLM" index="1">1</mcreference>

## 五. 引发的社会讨论（隐私、安全、公平性）

StableLM 的发布引发了广泛的社会讨论，主要集中在以下几个方面：

*   **开源与透明度**：Stability AI 强调其开源模型的透明性，认为开放模型代码和参数有助于研究人员和权威机构审查模型的运作，评估其质量、公平性和偏见。 <mcreference link="https://stability.ai/safety" index="2">2</mcreference> 这被视为提高 AI 技术可信度和减少偏见的重要举措。 <mcreference link="https://cryptosolopreneur.wordpress.com/2023/04/20/stabilityai-launches-stablelm-open-source-alternatives-to-chatgpt/" index="1">1</mcreference>
*   **数据隐私**：StableLM 被认为可能克服 ChatGPT 等闭源模型在数据隐私方面的一些问题，因为用户和开发者可以更清楚地了解模型的训练数据和运作方式。 <mcreference link="https://cryptosolopreneur.wordpress.com/2023/04/20/stabilityai-launches-stablelm-open-source-alternatives-to-chatgpt/" index="1">1</mcreference>
*   **安全性与滥用风险**：与所有强大的 AI 模型一样，开源的 StableLM 也引发了关于其可能被用于恶意目的的担忧，例如生成钓鱼邮件、辅助恶意软件攻击或传播虚假信息。 <mcreference link="https://techcrunch.com/2023/04/19/stability-ai-releases-chatgpt-like-language-models/" index="4">4</mcreference>
*   **公平性与偏见**：Stability AI 表示正通过“有意识地处理训练数据、评估指标和参数，以及模型的开源”来努力减少语言模型中的偏见。 <mcreference link="https://cryptosolopreneur.wordpress.com/2023/04/20/stabilityai-launches-stablelm-open-source-alternatives-to-chatgpt/" index="1">1</mcreference> 然而，模型是否仍会产生有偏见或有害的输出仍然是一个持续关注的问题。 <mcreference link="https://techcrunch.com/2023/04/19/stability-ai-releases-chatgpt-like-language-models/" index="4">4</mcreference>
*   **“无害性”声明**：在 'StableLM-Tuned-Alpha' 版本的系统提示中，明确指出模型是“乐于助人且无害的”，并且会“拒绝做任何可能被认为对用户有害的事情”，这表明 Stability AI 在尝试通过指令微调来引导模型的行为。 <mcreference link="https://github.com/Stability-AI/StableLM" index="1">1</mcreference>

目前，尚未有专门针对 StableLM 的具体政策变化或法规出台，但其发展无疑会受到全球范围内对大型语言模型监管趋势的影响。

## 六. 当前存在的局限性以及未来可能的发展方向

### 6.1 当前局限性

*   **幻觉与事实准确性**：与其他大型语言模型类似，StableLM 可能存在“幻觉”现象，即生成看似合理但不符合事实的信息。 <mcreference link="https://techcrunch.com/2023/04/19/stability-ai-releases-chatgpt-like-language-models/" index="4">4</mcreference>
*   **有害内容生成**：尽管 Stability AI 努力使其模型“无害”，但模型仍有可能在特定提示下生成不当或有害的内容。 <mcreference link="https://techcrunch.com/2023/04/19/stability-ai-releases-chatgpt-like-language-models/" index="4">4</mcreference>
*   **偏见问题**：虽然致力于减少偏见，但训练数据中固有的偏见仍可能在模型输出中体现。
*   **上下文理解与长程依赖**：尽管 Stable LM 2 1.6B 的上下文窗口达到了 4096 tokens，但在更长的对话或文档中保持连贯性和准确理解上下文仍然是一个挑战。
*   **资源消耗**：虽然 Stable LM 2 1.6B 这样的较小模型旨在降低资源门槛，但训练和大规模部署大型语言模型仍然需要大量的计算资源。

### 6.2 未来可能的发展方向

*   **更大规模的模型**：Stability AI 已表示计划发布更大参数规模的模型，例如 150 亿 (15B) 和 650 亿 (65B) 参数的模型，以期达到更高的性能。 <mcreference link="https://www.maginative.com/article/stability-ai-debuts-stablelm-accelerating-the-era-of-open-source-language-models/" index="3">3</mcreference>
*   **数据质量和多样性提升**：持续优化和扩展训练数据集，提高数据质量，纳入更多样化的数据源，以增强模型的知识覆盖面和鲁棒性。这是 Stable LM 2 1.6B 技术报告中提到的未来研究方向之一。
*   **缓解幻觉和提高可信度**：研究和应用新技术来减少模型的幻觉现象，提高生成内容的事实准确性和可信度。这也是 Stable LM 2 1.6B 技术报告中提到的未来研究方向。
*   **长上下文检索与理解**：进一步提升模型处理和理解长上下文信息的能力，以支持更复杂的任务和更自然的对话。Stable LM 2 1.6B 技术报告中提到了对长上下文检索的关注。
*   **条件计算 (Conditional Computation)**：探索如 Mixture of Experts (MoE) 等条件计算技术，以在不显著增加计算成本的情况下提升模型容量和性能。这是 Stable LM 2 1.6B 技术报告中提到的未来研究方向。
*   **多模态能力**：未来可能会向多模态发展，结合文本、图像等多种信息进行处理和生成，类似 Stability AI 在 Stable Diffusion 上的成功。
*   **效率和可部署性**：继续优化模型架构和推理引擎，提高运行效率，使其更容易在各种硬件平台（尤其是边缘设备）上部署。
*   **安全与对齐**：加强模型安全性的研究，开发更有效的对齐技术，确保模型行为符合人类价值观和社会规范。
*   **推动 AI 民主化**：继续坚持开源理念，为社区提供更强大、更易用的工具，促进 AI 技术的普及和创新。 <mcreference link="https://www.maginative.com/article/stability-ai-debuts-stablelm-accelerating-the-era-of-open-source-language-models/" index="3">3</mcreference>

通过克服现有技术障碍和解决相关的社会问题，StableLM 有望在未来继续发展，并在各个领域发挥更大的作用。

`;

        // Convert Markdown to HTML and inject it into the main content area
        // Wrap sections in cards for styling and animation
        function renderMarkdown() {
            const mainContentElement = document.getElementById('main-content');
            if (!mainContentElement) {
                console.error("renderMarkdown Error: 'main-content' element not found!");
                document.body.innerHTML = "Error: 'main-content' element not found! Critical error."; // Drastic fallback
                return;
            }

            console.log("renderMarkdown: Starting. Markdown content length:", markdownContent ? markdownContent.length : 0);

            if (!markdownContent || markdownContent.trim() === "") {
                mainContentElement.innerHTML = "<div class='content-card' style='opacity:1; transform:translateY(0);'><p>Error: Markdown content is empty or missing.</p></div>";
                console.warn("renderMarkdown: markdownContent is empty.");
                return;
            }

            try {
                const rawHtml = marked.parse(markdownContent.replace(/<mcreference[^>]*>[^<]*<\/mcreference>/g, ''));
                console.log("renderMarkdown: Parsed HTML length:", rawHtml ? rawHtml.length : 0);

                if (!rawHtml || rawHtml.trim() === "") {
                    mainContentElement.innerHTML = "<div class='content-card' style='opacity:1; transform:translateY(0);'><p>Error: Parsing markdown resulted in empty HTML. Check console for details (e.g., issues with 'marked' library or markdown syntax).</p></div>";
                    console.warn("renderMarkdown: marked.parse(markdownContent) resulted in empty HTML.");
                    return;
                }

                const tempDiv = document.createElement('div');
                tempDiv.innerHTML = rawHtml;

                if (tempDiv.children.length === 0 && rawHtml.trim() !== "") {
                    console.warn("renderMarkdown: No child elements found after parsing markdown, but raw HTML is not empty. Displaying raw HTML.");
                    mainContentElement.innerHTML = rawHtml;
                    addScrollAnimations();
                    return;
                }

                let cardHtml = '';
                let currentCardContent = '';
                let cardCount = 0;

                Array.from(tempDiv.children).forEach(node => {
                    if (node.tagName === 'H1') { // Skip the main H1, it's already in the header
                        return;
                    }

                    if (node.tagName === 'H2') {
                        if (currentCardContent) { // If there's content for a previous card, finalize it
                            cardHtml += `<div class="content-card scroll-animate">${currentCardContent}</div>`;
                            cardCount++;
                        }
                        currentCardContent = node.outerHTML; // Start new card with H2
                    } else {
                        // Append other content to the current card section
                        if (currentCardContent) { // If a card (started by H2) is active
                            currentCardContent += node.outerHTML;
                        } else if (cardHtml === '' && !currentCardContent) {
                            // This handles content that might appear before the very first H2 (after skipping H1)
                            // It starts the first card with this content.
                            currentCardContent = node.outerHTML;
                        }
                        // Content not fitting these conditions (e.g. orphaned after a card is closed but before new H2) might be skipped.
                        // Given the expected structure (H1, then H2 sections), this should be robust.
                    }
                });

                if (currentCardContent) { // Finalize the last card's content
                    cardHtml += `<div class="content-card scroll-animate">${currentCardContent}</div>`;
                    cardCount++;
                }

                console.log("renderMarkdown: Number of cards generated:", cardCount);
                console.log("renderMarkdown: Final cardHtml length:", cardHtml.length);

                if (cardHtml.trim() !== "") {
                    mainContentElement.innerHTML = cardHtml;
                } else if (rawHtml.trim() !== "") {
                    console.warn("renderMarkdown: Card generation resulted in empty HTML. Falling back to raw HTML.");
                    mainContentElement.innerHTML = rawHtml; // Fallback to raw HTML if card logic produced nothing but parsing was successful
                } else {
                    mainContentElement.innerHTML = "<div class='content-card' style='opacity:1; transform:translateY(0);'><p>Error: Failed to generate card HTML and raw HTML is also empty. Content processing failed.</p></div>";
                    console.error("renderMarkdown: Both cardHtml and rawHtml are effectively empty after processing.");
                }

                addScrollAnimations(); // Apply scroll animations to newly added cards

            } catch (error) {
                mainContentElement.innerHTML = `<div class='content-card' style='opacity:1; transform:translateY(0);'><p>Error during markdown rendering: ${error.message}. Check browser console for stack trace.</p></div>`;
                console.error("Error in renderMarkdown function execution:", error);
            }
        }

        // Scroll-triggered animations using a single IntersectionObserver
        function addScrollAnimations() {
            const animatedElements = document.querySelectorAll('.scroll-animate');
            if (animatedElements.length === 0) {
                // console.warn("addScrollAnimations: No '.scroll-animate' elements found to animate.");
                return;
            }

            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.style.opacity = '1';
                        entry.target.style.transform = 'translateY(0px)';
                        observer.unobserve(entry.target); // Animate only once
                    }
                });
            }, { threshold: 0.1 }); // Trigger when 10% of the element is visible

            animatedElements.forEach(el => {
                observer.observe(el);
            });
        }

        document.addEventListener('DOMContentLoaded', () => {
            try {
                renderMarkdown(); // This function now also calls addScrollAnimations internally
            } catch (e) {
                console.error("Error during initial page setup (DOMContentLoaded):", e);
                const mainContentElement = document.getElementById('main-content');
                if (mainContentElement) {
                    // Display a user-friendly error message on the page
                    mainContentElement.innerHTML = `
                        <div class="content-card" style="color: #ff6b6b; background: rgba(255,255,255,0.1); opacity:1; transform:translateY(0);">
                            <h2 style="color: #ff6b6b;"><i class="fas fa-exclamation-triangle icon"></i> 页面加载错误</h2>
                            <p>抱歉，加载此页面内容时发生错误。</p>
                            <p><strong>错误详情:</strong> ${e.message}</p>
                            <p>请尝试刷新页面，或按 F12 打开浏览器控制台查看更多技术信息。</p>
                        </div>`;
                } else {
                    // Fallback if main-content is not even available
                    document.body.innerHTML = `错误: ${e.message}. 未找到主要内容容器。`;
                }
            }
        });

    </script>
</body>
<html>
